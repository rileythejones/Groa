{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v-p9hljqMyQh",
    "outputId": "cdc5fbff-4b58-4185-c291-d63a17f6adc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35371"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "watched_train = pickle.load(open('watched_train_4.sav', 'rb'))\n",
    "len(watched_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QH_POwX6OH-R"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')\n",
    "    \n",
    "def fill_id(id):\n",
    "    \"\"\"Adds leading zeroes back if necessary. This makes the id match the database.\"\"\"\n",
    "    if len(str(id)) < 7:\n",
    "        length = len(str(id))\n",
    "        id = \"0\"*(7 - length) + str(id)\n",
    "    return str(id)\n",
    "    \n",
    "def df_to_id_list(df, id_book):\n",
    "    \"\"\"Converts dataframe of movies to a list of the IDs for those movies.\n",
    "\n",
    "    Every title in the input dataframe is checked against the local file, which\n",
    "    includes all the titles and IDs in our database. For anything without a match,\n",
    "    replace the non-alphanumeric characters with wildcards, and query the database\n",
    "    for matches.\n",
    "    \"\"\"\n",
    "    #df['Year'] = df['Year'].astype(int).astype(str) #Changed made as required by migrating to DB (Niki)\n",
    "    matched = pd.merge(df, id_book,\n",
    "                left_on=['Name', 'Year'], right_on=['primaryTitle', 'startYear'],\n",
    "                how='inner')\n",
    "    ids = matched['tconst'].astype(str).tolist()\n",
    "    final_ratings = []\n",
    "    names = df.Name.tolist()\n",
    "    years = [int(year) for year in df.Year.tolist()]\n",
    "    if 'Rating' in df.columns:\n",
    "        stars = [int(rating) for rating in df.Rating.tolist()]\n",
    "        info = list(zip(names, years, stars))\n",
    "        final_ratings = matched['Rating'].astype(int).tolist()\n",
    "    else:\n",
    "        info = list(zip(names, years, list(range(len(years)))))\n",
    "    missed = [x for x in info if x[0] not in matched['primaryTitle'].tolist()]\n",
    "    for i, j, k in missed:\n",
    "        i = re.sub('[^\\s0-9a-zA-Z\\s]+', '%', i)\n",
    "        try:\n",
    "            cursor_dog.execute(f\"\"\"\n",
    "                SELECT movie_id, original_title, primary_title\n",
    "                FROM movies\n",
    "                WHERE primary_title ILIKE '{i}' AND start_year = {j}\n",
    "                  OR original_title ILIKE '{i}' AND start_year = {j}\n",
    "                ORDER BY runtime_minutes DESC\n",
    "                LIMIT 1\"\"\")\n",
    "            id = cursor_dog.fetchone()[0]\n",
    "            ids.append(id)\n",
    "            final_ratings.append(k)\n",
    "        except:\n",
    "            continue\n",
    "    ids = [fill_id(id) for id in ids]\n",
    "    final_ratings = [x*2 for x in final_ratings]\n",
    "    ratings_dict = dict(zip(ids, final_ratings))    \n",
    "    return tuple([ids, ratings_dict])\n",
    "    \n",
    "def prep_data(ratings_df, watched_df=None, watchlist_df=None, \n",
    "                   good_threshold=4, bad_threshold=3):\n",
    "    \"\"\"Converts dataframes of exported Letterboxd data to lists of movie_ids.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ratings_df : pd dataframe\n",
    "        Letterboxd ratings.\n",
    "\n",
    "    watched_df : pd dataframe\n",
    "        Letterboxd watch history.\n",
    "\n",
    "    watchlist_df : pd dataframe\n",
    "        Letterboxd list of movies the user wants to watch.\n",
    "        Used in val_list for scoring the model's performance.\n",
    "\n",
    "    good_threshold : int\n",
    "        Minimum star rating (10pt scale) for a movie to be considered \"enjoyed\" by the user.\n",
    "\n",
    "    bad_threshold : int\n",
    "        Maximum star rating (10pt scale) for a movie to be considered \"disliked\" by the user.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of lists of ids.\n",
    "        (good_list, bad_list, hist_list, val_list)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # try to read Letterboxd user data\n",
    "        # drop rows with nulls in the columns we use\n",
    "        ratings_df = ratings_df.dropna(axis=0, subset=['Rating', 'Name', 'Year'])\n",
    "        # split according to user rating\n",
    "        good_df = ratings_df[ratings_df['Rating'] >= good_threshold]        \n",
    "        bad_df = ratings_df[ratings_df['Rating'] <= bad_threshold]\n",
    "        neutral_df = ratings_df[(ratings_df['Rating'] > bad_threshold) & (ratings_df['Rating'] < good_threshold)]\n",
    "        # convert dataframes to lists\n",
    "        good_list, good_dict = df_to_id_list(good_df, id_book)\n",
    "        bad_list, bad_dict = df_to_id_list(bad_df, id_book)\n",
    "        neutral_list, neutral_dict = df_to_id_list(neutral_df, id_book)\n",
    "    except KeyError:\n",
    "        # Try to read IMDb user data\n",
    "        # strip ids of \"tt\" prefix\n",
    "        ratings_df['movie_id'] = ratings_df['Const'].str.lstrip(\"tt\")\n",
    "        # drop rows with nulls in the columns we use\n",
    "        ratings_df = ratings_df.dropna(axis=0, subset=['Your Rating', 'Year'])\n",
    "        # split according to user rating\n",
    "        good_df = ratings_df[ratings_df['Your Rating'] >= good_threshold*2]\n",
    "        bad_df = ratings_df[ratings_df['Your Rating'] <= bad_threshold*2]\n",
    "        neutral_df = ratings_df[(ratings_df['Your Rating'] > bad_threshold*2) & (ratings_df['Your Rating'] < good_threshold*2)]\n",
    "        # convert dataframes to lists\n",
    "        good_list = good_df['movie_id'].to_list()\n",
    "        bad_list = bad_df['movie_id'].to_list()\n",
    "        neutral_list = neutral_df['movie_id'].to_list()\n",
    "    except Exception as e:\n",
    "        # can't read the dataframe as Letterboxd or IMDb user data\n",
    "        print(\"This dataframe has columns:\", ratings_df.columns)\n",
    "        raise Exception(e)\n",
    "        \n",
    "    ratings_dict = dict(list(good_dict.items()) + list(bad_dict.items()) + list(neutral_dict.items()))\n",
    "\n",
    "    if watched_df is not None:\n",
    "        # Construct list of watched movies that aren't rated \"good\" or \"bad\"\n",
    "        # First, get a set of identified IDs.\n",
    "        rated_names = set(good_df.Name.tolist() + bad_df.Name.tolist() + neutral_list)\n",
    "        # drop nulls from watched dataframe\n",
    "        full_history = watched_df.dropna(axis=0, subset=['Name', 'Year'])\n",
    "        # get list of watched movies that haven't been rated\n",
    "        hist_list = df_to_id_list(full_history[~full_history['Name'].isin(rated_names)], id_book)[0]\n",
    "        # add back list of \"neutral\" movies (whose IDs we already found before)\n",
    "        hist_list = hist_list + neutral_list\n",
    "    else: hist_list = neutral_list\n",
    "\n",
    "    if watchlist_df is not None:\n",
    "        try:\n",
    "            watchlist_df = watchlist_df.dropna(axis=0, subset=['Name', 'Year'])\n",
    "            val_list = df_to_id_list(watchlist_df, id_book)[0]\n",
    "        except KeyError:\n",
    "            watchlist_df = watchlist_df.dropna(axis=0, subset=['Const', 'Year'])\n",
    "            watchlist_df['movie_id'] = watchlist_df['Const'].str.lstrip(\"tt\")\n",
    "            val_list = watchlist_df['movie_id'].tolist()\n",
    "    else: val_list = []\n",
    "\n",
    "    return (good_list, bad_list, hist_list, val_list, ratings_dict)\n",
    "\n",
    "class Recommender(object):\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"Initialize model with name of .model file\"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.model = None\n",
    "        self.cursor_dog = c # set to this notebook's connection\n",
    "        self.id_book = pd.read_csv('title_basics_small.csv')\n",
    "\n",
    "    def connect_db(self):\n",
    "        \"\"\"connect to database, create cursor.\n",
    "        In the notebook, this isn't used, and all connections are \n",
    "        handled through the notebook's global connection at the top.\"\"\"\n",
    "        # connect to database\n",
    "        connection = psycopg2.connect(\n",
    "            database  = \"postgres\",\n",
    "            user      = \"postgres\",\n",
    "            password  = os.getenv('DB_PASSWORD'),\n",
    "            host      = \"movie-rec-scrape.cvslmiksgnix.us-east-1.rds.amazonaws.com\",\n",
    "            port      = '5432'\n",
    "        )\n",
    "        # create cursor that is used throughout\n",
    "\n",
    "        try:\n",
    "            self.cursor_dog = connection.cursor()\n",
    "            print(\"Connected!\")\n",
    "        except:\n",
    "            print(\"Connection problem chief!\")\n",
    "\n",
    "    def _get_model(self):\n",
    "        \"\"\"Get the model object for this instance, loading it if it's not already loaded.\"\"\"\n",
    "        if self.model == None:\n",
    "            model_path = self.model_path\n",
    "            w2v_model = gensim.models.Word2Vec.load(model_path)\n",
    "            # Keep only the normalized vectors.\n",
    "            # This saves memory but makes the model untrainable (read-only).\n",
    "            w2v_model.init_sims(replace=True)\n",
    "            self.model = w2v_model\n",
    "        return self.model\n",
    "\n",
    "    def _get_info(self, id, score=None):\n",
    "        \"\"\"Takes an id string and returns the movie info with a url.\"\"\"\n",
    "        try:\n",
    "            info_query = f\"\"\"\n",
    "            SELECT m.primary_title, m.start_year, r.average_rating, r.num_votes\n",
    "            FROM movies m\n",
    "            JOIN ratings r ON m.movie_id = r.movie_id\n",
    "            WHERE m.movie_id = '{id}'\"\"\"\n",
    "            self.cursor_dog.execute(info_query)\n",
    "        except Exception as e:\n",
    "            return tuple([f\"Movie title unknown. ID:{id}\", None, None, None, None, None, id])\n",
    "\n",
    "        t = self.cursor_dog.fetchone()\n",
    "        if t:\n",
    "            title = tuple([t[0], t[1], f\"https://www.imdb.com/title/tt{id}/\", t[2], t[3], score, id])\n",
    "            return title\n",
    "        else:\n",
    "            return tuple([f\"Movie title not retrieved. ID:{id}\", None, None, None, None, None, id])\n",
    "\n",
    "    def get_most_similar_title(self, id, id_list):\n",
    "        \"\"\"Get the title of the most similar movie to id from id_list\"\"\"\n",
    "        clf = self._get_model()\n",
    "        vocab = clf.wv.vocab\n",
    "        if id not in vocab:\n",
    "            return \"\"\n",
    "        id_list = [id for id in id_list if id in vocab] # ensure all in vocab\n",
    "        id_book = self.id_book\n",
    "        match = clf.wv.most_similar_to_given(id, id_list)\n",
    "        return id_book['primaryTitle'].loc[id_book['tconst'] == int(match)].values[0]\n",
    "\n",
    "    def predict(self, input, bad_movies=[], hist_list=[], val_list=[],\n",
    "                ratings_dict = {}, checked_list=[], rejected_list=[],\n",
    "                n=50, harshness=1, rec_movies=True,\n",
    "                show_vibes=False, scoring=False, return_scores=False):\n",
    "        \"\"\"Returns a list of recommendations and useful metadata, given a pretrained\n",
    "        word2vec model and a list of movies.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "            input : iterable\n",
    "                List of movies that the user likes.\n",
    "\n",
    "            bad_movies : iterable\n",
    "                List of movies that the user dislikes.\n",
    "\n",
    "            hist_list : iterable\n",
    "                List of movies the user has seen.\n",
    "\n",
    "            val_list : iterable\n",
    "                List of movies the user has already indicated interest in.\n",
    "                Example: https://letterboxd.com/tabula_rasta/watchlist/\n",
    "                People really load these up over the years, and so they make for \n",
    "                the best validation set we can ask for with current resources.\n",
    "\n",
    "            ratings_dict : dictionary\n",
    "                Dictionary of movie_id keys, user rating values.\n",
    "\n",
    "            checked_list : iterable\n",
    "                List of movies the user likes on the feedback form.\n",
    "\n",
    "            rejected_list : iterable\n",
    "                List of movies the user dislikes on the feedback form.\n",
    "\n",
    "            n : int\n",
    "                Number of recommendations to return.\n",
    "\n",
    "            harshness : int\n",
    "                Weighting to apply to disliked movies.\n",
    "                Ex:\n",
    "                    1 - most strongly account for disliked movies.\n",
    "                    3 - divide \"disliked movies\" vector by 3.\n",
    "\n",
    "            rec_movies : boolean\n",
    "                If False, doesn't return movie recommendations (used for scoring).\n",
    "\n",
    "            show_vibes : boolean\n",
    "                If True, prints out the dupes as a feature.\n",
    "                These movies are closest to the user's taste vector, \n",
    "                indicating some combination of importance and popularity.\n",
    "\n",
    "            scoring : boolean\n",
    "                If True, prints out the validation score.\n",
    "            \n",
    "            return_scores : boolean\n",
    "                If True, skips printing out\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A list of tuples\n",
    "            (Title, Year, IMDb URL, Average Rating, Number of Votes, Similarity score)\n",
    "        \"\"\"\n",
    "\n",
    "        clf = self._get_model()\n",
    "        dupes = []                 # list for storing duplicates for scoring\n",
    "\n",
    "        def _aggregate_vectors(movies, feedback_list=[]):\n",
    "            \"\"\"Gets the vector average of a list of movies.\"\"\"\n",
    "            movie_vec = []\n",
    "            for i in movies:\n",
    "                try:\n",
    "                    m_vec = clf[i]  # get the vector for each movie\n",
    "                    if ratings_dict:\n",
    "                        try:\n",
    "                            r = ratings_dict[i] # get user_rating for each movie\n",
    "                            # Use a polynomial to weight the movie by rating.\n",
    "                            # This equation is somewhat arbitrary. I just fit a polynomial\n",
    "                            # to some weights that look good. The effect is to raise\n",
    "                            # the importance of 1, 2, 9, and 10 star ratings to about 1.8.\n",
    "                            w = ((r**3)*-0.00143) + ((r**2)*0.0533) + (r*-0.4695) + 2.1867\n",
    "                            m_vec = m_vec * w\n",
    "                        except KeyError:\n",
    "                            continue\n",
    "                    movie_vec.append(m_vec)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "            if feedback_list:\n",
    "                for i in feedback_list:\n",
    "                    try:\n",
    "                        f_vec = clf[i]\n",
    "                        movie_vec.append(f_vec*1.8) # weight feedback by changing multiplier here\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "            return np.mean(movie_vec, axis=0)\n",
    "\n",
    "        def _similar_movies(v, bad_movies=[], n=50):\n",
    "            \"\"\"Aggregates movies and finds n vectors with highest cosine similarity.\"\"\"\n",
    "            if bad_movies:\n",
    "                v = _remove_dislikes(bad_movies, v, harshness=harshness)\n",
    "            return clf.similar_by_vector(v, topn= n+1)[1:]\n",
    "\n",
    "        def _remove_dupes(recs, input, bad_movies, hist_list=[], feedback_list=[]):\n",
    "            \"\"\"remove any recommended IDs that were in the input list\"\"\"\n",
    "            all_rated = input + bad_movies + hist_list + feedback_list\n",
    "            nonlocal dupes\n",
    "            dupes = [x for x in recs if x[0] in input]\n",
    "            return [x for x in recs if x[0] not in all_rated]\n",
    "\n",
    "        def _remove_dislikes(bad_movies, good_movies_vec, rejected_list=[], harshness=1):\n",
    "            \"\"\"Takes a list of movies that the user dislikes.\n",
    "            Their embeddings are averaged,\n",
    "            and subtracted from the input.\"\"\"\n",
    "            bad_vec = _aggregate_vectors(bad_movies, rejected_list)\n",
    "            bad_vec = bad_vec / harshness\n",
    "            return good_movies_vec - bad_vec\n",
    "\n",
    "        def _score_model(recs, val_list):\n",
    "            \"\"\"Returns the number of recs that were already in the user's watchlist. Validation!\"\"\"\n",
    "            ids = [x[0] for x in recs]\n",
    "            return len(list(set(ids) & set(val_list)))\n",
    "\n",
    "        aggregated = _aggregate_vectors(input, checked_list)\n",
    "        recs = _similar_movies(aggregated, bad_movies, n=n)\n",
    "        recs = _remove_dupes(recs, input, bad_movies, hist_list, checked_list + rejected_list)\n",
    "        formatted_recs = [self._get_info(x[0], x[1]) for x in recs]\n",
    "        if val_list:\n",
    "            if return_scores:\n",
    "                return tuple([_score_model(recs, val_list), sum([i[3] for i in formatted_recs if i[3] is not None])/len(formatted_recs)])\n",
    "            elif scoring:\n",
    "                print(f\"The model recommended {_score_model(recs, val_list)} movies that were on the watchlist!\\n\")\n",
    "                print(f\"\\t\\t Average Rating: {sum([i[3] for i in formatted_recs if i[3] is not None])/len(formatted_recs)}\\n\")\n",
    "        if show_vibes:\n",
    "            print(\"You'll get along with people who like: \\n\")\n",
    "            for x in dupes:\n",
    "                print(self._get_info(x[0], x[1]))\n",
    "            print('\\n')\n",
    "        if rec_movies:\n",
    "            return formatted_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "tewwzvajQyW3",
    "outputId": "6fa1b6d1-9c6a-49f2-fc7c-8200a9d96556"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\users\\ryloid\\appdata\\roaming\\python\\python37\\site-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.3, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    }
   ],
   "source": [
    "! pip3 install psycopg2-binary --user\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "from getpass import getpass\n",
    "\n",
    "# connect to database. Never save your password to a notebook.\n",
    "connection = psycopg2.connect(\n",
    "    database  = \"postgres\",\n",
    "    user      = \"postgres\",\n",
    "    password  = 'lambdaschoolgroa',\n",
    "#     password  = getpass(), # secure password entry. Enter DB password in the prompt and press Enter.\n",
    "    host      = \"movie-rec-scrape.cvslmiksgnix.us-east-1.rds.amazonaws.com\",\n",
    "#     host      = \"groadb.cbayt2opbptw.us-east-1.rds.amazonaws.com\",\n",
    "    port      = '5432'\n",
    ")\n",
    "\n",
    "# create cursor that is used throughout\n",
    "try:\n",
    "    c = connection.cursor()\n",
    "    print(\"Connected!\")\n",
    "except Exception as e:\n",
    "    print(\"Connection problem chief!\\n\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT \"rt.Date\", \"rt.Name\", \"rt.Year\", \"rt.Letterboxd_URI\", \"rt.Rating\" FROM \"test_ratings\" \"rt\" where \"rt.userid=1111\";\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"SELECT \"rt.Date\", \"rt.Name\", \"rt.Year\", \"rt.Letterboxd_URI\", \"rt.Rating\" FROM \"test_ratings\" \"rt\" where \"rt.userid=1111\";\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OuJQ6tNHZaOP"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'rt.Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8d8794c7d242>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings_sql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Year'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Letterboxd_URI'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Year'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'int64'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# c.execute(\"SELECT wl.Date, wl.Name, wl.Year, wl.Letterboxd_URI FROM test_watchlist wl where wl.userid=userid_temp;\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\groa\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   5863\u001b[0m                     results.append(\n\u001b[0;32m   5864\u001b[0m                         col.astype(\n\u001b[1;32m-> 5865\u001b[1;33m                             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5866\u001b[0m                         )\n\u001b[0;32m   5867\u001b[0m                     )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\groa\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   5880\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5881\u001b[0m             new_data = self._data.astype(\n\u001b[1;32m-> 5882\u001b[1;33m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5883\u001b[0m             )\n\u001b[0;32m   5884\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\groa\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\groa\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\groa\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_astype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_astype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\groa\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m                     \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m                     \u001b[0mvals1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m                     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[1;31m# TODO(extension)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\groa\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    705\u001b[0m         \u001b[1;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'rt.Year'"
     ]
    }
   ],
   "source": [
    "# Get data from DB (Niki)\n",
    "from pandas import DataFrame\n",
    "\n",
    "userid_temp=1111\n",
    "\n",
    "c.execute(f\"SELECT 'rt.Date', 'rt.Name', 'rt.Year', 'rt.Letterboxd_URI', 'rt.Rating' FROM test_ratings rt where rt.userid={userid_temp};\")\n",
    "ratings_sql= c.fetchall()\n",
    "ratings = DataFrame(ratings_sql, columns = ['Date', 'Name', 'Year', 'Letterboxd_URI', 'Rating'])\n",
    "ratings= ratings.dropna()\n",
    "ratings.astype({'Year': 'int64'}).dtypes\n",
    "\n",
    "# c.execute(\"SELECT wl.Date, wl.Name, wl.Year, wl.Letterboxd_URI FROM test_watchlist wl where wl.userid=userid_temp;\")\n",
    "# watchlist_sql= c.fetchall()\n",
    "# watchlist = DataFrame(watchlist_sql, columns = ['Date', 'Name', 'Year', 'Letterboxd_URI'])\n",
    "# watchlist = watchlist.dropna()\n",
    "# watchlist.astype({'Year': 'int64'}).dtypes\n",
    "\n",
    "# c.execute(\"SELECT w.Date, w.Name, w.Year, w.Letterboxd_URI FROM test_watched w where w.userd=userid_temp;\")\n",
    "# watched_sql= c.fetchall()\n",
    "# watched = DataFrame(watched_sql, columns = ['Date', 'Name', 'Year', 'Letterboxd_URI'])\n",
    "# watched = watched.dropna()\n",
    "# watched.astype({'Year': 'int64'}).dtypes\n",
    "\n",
    "# c.execute(\"SELECT tbs.tconst, tbs.primaryTitle, tbs.originalTitle, tbs.startYear FROM test_title_basics_small tbs where tbs.userd=userid_temp;\")\n",
    "# title_basics_small_sql= c.fetchall()\n",
    "# id_book = DataFrame(title_basics_small_sql, columns = ['tconst', 'primaryTitle', 'originalTitle', 'startYear'])\n",
    "# id_book = id_book.dropna()\n",
    "# id_book.astype({'startYear': 'int64'}).dtypes\n",
    "\n",
    "# note: if you import IMDb data, it's currently encoded 'cp1252' (but they may someday switch to utf-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Letterboxd_URI</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt.Date</td>\n",
       "      <td>rt.Name</td>\n",
       "      <td>rt.Year</td>\n",
       "      <td>rt.Letterboxd_URI</td>\n",
       "      <td>rt.Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt.Date</td>\n",
       "      <td>rt.Name</td>\n",
       "      <td>rt.Year</td>\n",
       "      <td>rt.Letterboxd_URI</td>\n",
       "      <td>rt.Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt.Date</td>\n",
       "      <td>rt.Name</td>\n",
       "      <td>rt.Year</td>\n",
       "      <td>rt.Letterboxd_URI</td>\n",
       "      <td>rt.Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt.Date</td>\n",
       "      <td>rt.Name</td>\n",
       "      <td>rt.Year</td>\n",
       "      <td>rt.Letterboxd_URI</td>\n",
       "      <td>rt.Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt.Date</td>\n",
       "      <td>rt.Name</td>\n",
       "      <td>rt.Year</td>\n",
       "      <td>rt.Letterboxd_URI</td>\n",
       "      <td>rt.Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>rt.Date</td>\n",
       "      <td>rt.Name</td>\n",
       "      <td>rt.Year</td>\n",
       "      <td>rt.Letterboxd_URI</td>\n",
       "      <td>rt.Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>rt.Date</td>\n",
       "      <td>rt.Name</td>\n",
       "      <td>rt.Year</td>\n",
       "      <td>rt.Letterboxd_URI</td>\n",
       "      <td>rt.Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>rt.Date</td>\n",
       "      <td>rt.Name</td>\n",
       "      <td>rt.Year</td>\n",
       "      <td>rt.Letterboxd_URI</td>\n",
       "      <td>rt.Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>rt.Date</td>\n",
       "      <td>rt.Name</td>\n",
       "      <td>rt.Year</td>\n",
       "      <td>rt.Letterboxd_URI</td>\n",
       "      <td>rt.Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>rt.Date</td>\n",
       "      <td>rt.Name</td>\n",
       "      <td>rt.Year</td>\n",
       "      <td>rt.Letterboxd_URI</td>\n",
       "      <td>rt.Rating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date     Name     Year     Letterboxd_URI     Rating\n",
       "0    rt.Date  rt.Name  rt.Year  rt.Letterboxd_URI  rt.Rating\n",
       "1    rt.Date  rt.Name  rt.Year  rt.Letterboxd_URI  rt.Rating\n",
       "2    rt.Date  rt.Name  rt.Year  rt.Letterboxd_URI  rt.Rating\n",
       "3    rt.Date  rt.Name  rt.Year  rt.Letterboxd_URI  rt.Rating\n",
       "4    rt.Date  rt.Name  rt.Year  rt.Letterboxd_URI  rt.Rating\n",
       "..       ...      ...      ...                ...        ...\n",
       "825  rt.Date  rt.Name  rt.Year  rt.Letterboxd_URI  rt.Rating\n",
       "826  rt.Date  rt.Name  rt.Year  rt.Letterboxd_URI  rt.Rating\n",
       "827  rt.Date  rt.Name  rt.Year  rt.Letterboxd_URI  rt.Rating\n",
       "828  rt.Date  rt.Name  rt.Year  rt.Letterboxd_URI  rt.Rating\n",
       "829  rt.Date  rt.Name  rt.Year  rt.Letterboxd_URI  rt.Rating\n",
       "\n",
       "[830 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rSwD8bVJxrG6"
   },
   "outputs": [],
   "source": [
    "# prep user data\n",
    "good_list, bad_list, hist_list, val_list, ratings_dict = prep_data(\n",
    "                                    ratings, watchlist_df=watchlist, watched_df=watched, good_threshold=4, bad_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "M0Q3K8mdQkb8",
    "outputId": "dbf0bfb3-58b4-4bbd-d5fc-0c94377ca225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model recommended 24 movies that were on the watchlist!\n",
      "\n",
      "\t\t Average Rating: 7.951162790697674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = Recommender('w2v_limitingfactor_v3.51.model')\n",
    "s.predict(good_list, bad_list, hist_list, val_list, ratings_dict, n=100, harshness=1, rec_movies=False, scoring=True,)\n",
    "# s.predict(aj2, n=100, harshness=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "0221.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "groa (Python3.7)",
   "language": "python",
   "name": "groa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
