{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v-p9hljqMyQh",
    "outputId": "cdc5fbff-4b58-4185-c291-d63a17f6adc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35371"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "watched_train = pickle.load(open('watched_train_4.sav', 'rb'))\n",
    "len(watched_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "bookie = pd.read_csv('exported_data/title_basics_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305342, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QH_POwX6OH-R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryloid\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')\n",
    "    \n",
    "def fill_id(id):\n",
    "    \"\"\"Adds leading zeroes back if necessary. This makes the id match the database.\"\"\"\n",
    "    if len(str(id)) < 7:\n",
    "        length = len(str(id))\n",
    "        id = \"0\"*(7 - length) + str(id)\n",
    "    return str(id)\n",
    "    \n",
    "def df_to_id_list(df, id_book):\n",
    "    \"\"\"Converts dataframe of movies to a list of the IDs for those movies.\n",
    "\n",
    "    Every title in the input dataframe is checked against the local file, which\n",
    "    includes all the titles and IDs in our database. For anything without a match,\n",
    "    replace the non-alphanumeric characters with wildcards, and query the database\n",
    "    for matches.\n",
    "    \"\"\"\n",
    "    #df['Year'] = df['Year'].astype(int).astype(str) #Changed made as required by migrating to DB\n",
    "    matched = pd.merge(df, id_book,\n",
    "                left_on=['Name', 'Year'], right_on=['primaryTitle', 'startYear'],\n",
    "                how='inner')\n",
    "    ids = matched['tconst'].astype(str).tolist()\n",
    "    final_ratings = []\n",
    "    names = df.Name.tolist()\n",
    "    years = [int(year) for year in df.Year.tolist()]\n",
    "    if 'Rating' in df.columns:\n",
    "        stars = [int(rating) for rating in df.Rating.tolist()]\n",
    "        info = list(zip(names, years, stars))\n",
    "        final_ratings = matched['Rating'].astype(int).tolist()\n",
    "    else:\n",
    "        info = list(zip(names, years, list(range(len(years)))))\n",
    "    missed = [x for x in info if x[0] not in matched['primaryTitle'].tolist()]\n",
    "    for i, j, k in missed:\n",
    "        i = re.sub('[^\\s0-9a-zA-Z\\s]+', '%', i)\n",
    "        try:\n",
    "            cursor_dog.execute(f\"\"\"\n",
    "                SELECT movie_id, original_title, primary_title\n",
    "                FROM movies\n",
    "                WHERE primary_title ILIKE '{i}' AND start_year = {j}\n",
    "                  OR original_title ILIKE '{i}' AND start_year = {j}\n",
    "                ORDER BY runtime_minutes DESC\n",
    "                LIMIT 1\"\"\")\n",
    "            id = cursor_dog.fetchone()[0]\n",
    "            ids.append(id)\n",
    "            final_ratings.append(k)\n",
    "        except:\n",
    "            continue\n",
    "    ids = [fill_id(id) for id in ids]\n",
    "    final_ratings = [x*2 for x in final_ratings]\n",
    "    ratings_dict = dict(zip(ids, final_ratings))    \n",
    "    return tuple([ids, ratings_dict])\n",
    "    \n",
    "def prep_data(ratings_df, watched_df=None, watchlist_df=None, \n",
    "                   good_threshold=4, bad_threshold=3):\n",
    "    \"\"\"Converts dataframes of exported Letterboxd data to lists of movie_ids.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ratings_df : pd dataframe\n",
    "        Letterboxd ratings.\n",
    "\n",
    "    watched_df : pd dataframe\n",
    "        Letterboxd watch history.\n",
    "\n",
    "    watchlist_df : pd dataframe\n",
    "        Letterboxd list of movies the user wants to watch.\n",
    "        Used in val_list for scoring the model's performance.\n",
    "\n",
    "    good_threshold : int\n",
    "        Minimum star rating (10pt scale) for a movie to be considered \"enjoyed\" by the user.\n",
    "\n",
    "    bad_threshold : int\n",
    "        Maximum star rating (10pt scale) for a movie to be considered \"disliked\" by the user.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of lists of ids.\n",
    "        (good_list, bad_list, hist_list, val_list)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # try to read Letterboxd user data\n",
    "        # drop rows with nulls in the columns we use\n",
    "        ratings_df = ratings_df.dropna(axis=0, subset=['Rating', 'Name', 'Year'])\n",
    "        # split according to user rating\n",
    "        good_df = ratings_df[ratings_df['Rating'] >= good_threshold]        \n",
    "        bad_df = ratings_df[ratings_df['Rating'] <= bad_threshold]\n",
    "        neutral_df = ratings_df[(ratings_df['Rating'] > bad_threshold) & (ratings_df['Rating'] < good_threshold)]\n",
    "        # convert dataframes to lists\n",
    "        good_list, good_dict = df_to_id_list(good_df, id_book)\n",
    "        bad_list, bad_dict = df_to_id_list(bad_df, id_book)\n",
    "        neutral_list, neutral_dict = df_to_id_list(neutral_df, id_book)\n",
    "    except KeyError:\n",
    "        # Try to read IMDb user data\n",
    "        # strip ids of \"tt\" prefix\n",
    "        ratings_df['movie_id'] = ratings_df['Const'].str.lstrip(\"tt\")\n",
    "        # drop rows with nulls in the columns we use\n",
    "        ratings_df = ratings_df.dropna(axis=0, subset=['Your Rating', 'Year'])\n",
    "        # split according to user rating\n",
    "        good_df = ratings_df[ratings_df['Your Rating'] >= good_threshold*2]\n",
    "        bad_df = ratings_df[ratings_df['Your Rating'] <= bad_threshold*2]\n",
    "        neutral_df = ratings_df[(ratings_df['Your Rating'] > bad_threshold*2) & (ratings_df['Your Rating'] < good_threshold*2)]\n",
    "        # convert dataframes to lists\n",
    "        good_list = good_df['movie_id'].to_list()\n",
    "        bad_list = bad_df['movie_id'].to_list()\n",
    "        neutral_list = neutral_df['movie_id'].to_list()\n",
    "    except Exception as e:\n",
    "        # can't read the dataframe as Letterboxd or IMDb user data\n",
    "        print(\"This dataframe has columns:\", ratings_df.columns)\n",
    "        raise Exception(e)\n",
    "        \n",
    "    ratings_dict = dict(list(good_dict.items()) + list(bad_dict.items()) + list(neutral_dict.items()))\n",
    "\n",
    "    if watched_df is not None:\n",
    "        # Construct list of watched movies that aren't rated \"good\" or \"bad\"\n",
    "        # First, get a set of identified IDs.\n",
    "        rated_names = set(good_df.Name.tolist() + bad_df.Name.tolist() + neutral_list)\n",
    "        # drop nulls from watched dataframe\n",
    "        full_history = watched_df.dropna(axis=0, subset=['Name', 'Year'])\n",
    "        # get list of watched movies that haven't been rated\n",
    "        hist_list = df_to_id_list(full_history[~full_history['Name'].isin(rated_names)], id_book)[0]\n",
    "        # add back list of \"neutral\" movies (whose IDs we already found before)\n",
    "        hist_list = hist_list + neutral_list\n",
    "    else: hist_list = neutral_list\n",
    "\n",
    "    if watchlist_df is not None:\n",
    "        try:\n",
    "            watchlist_df = watchlist_df.dropna(axis=0, subset=['Name', 'Year'])\n",
    "            val_list = df_to_id_list(watchlist_df, id_book)[0]\n",
    "        except KeyError:\n",
    "            watchlist_df = watchlist_df.dropna(axis=0, subset=['Const', 'Year'])\n",
    "            watchlist_df['movie_id'] = watchlist_df['Const'].str.lstrip(\"tt\")\n",
    "            val_list = watchlist_df['movie_id'].tolist()\n",
    "    else: val_list = []\n",
    "\n",
    "    return (good_list, bad_list, hist_list, val_list, ratings_dict)\n",
    "\n",
    "class Recommender(object):\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"Initialize model with name of .model file\"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.model = None\n",
    "        self.cursor_dog = c # set to this notebook's connection\n",
    "        self.id_book = pd.read_csv('exported_data/title_basics_small.csv')\n",
    "\n",
    "    def connect_db(self):\n",
    "        \"\"\"connect to database, create cursor.\n",
    "        In the notebook, this isn't used, and all connections are \n",
    "        handled through the notebook's global connection at the top.\"\"\"\n",
    "        # connect to database\n",
    "        connection = psycopg2.connect(\n",
    "            database  = \"postgres\",\n",
    "            user      = \"postgres\",\n",
    "            password  = os.getenv('DB_PASSWORD'),\n",
    "            host      = \"movie-rec-scrape.cvslmiksgnix.us-east-1.rds.amazonaws.com\",\n",
    "            port      = '5432'\n",
    "        )\n",
    "        # create cursor that is used throughout\n",
    "\n",
    "        try:\n",
    "            self.cursor_dog = connection.cursor()\n",
    "            print(\"Connected!\")\n",
    "        except:\n",
    "            print(\"Connection problem chief!\")\n",
    "\n",
    "    def _get_model(self):\n",
    "        \"\"\"Get the model object for this instance, loading it if it's not already loaded.\"\"\"\n",
    "        if self.model == None:\n",
    "            model_path = self.model_path\n",
    "            w2v_model = gensim.models.Word2Vec.load(model_path)\n",
    "            # Keep only the normalized vectors.\n",
    "            # This saves memory but makes the model untrainable (read-only).\n",
    "            w2v_model.init_sims(replace=True)\n",
    "            self.model = w2v_model\n",
    "        return self.model\n",
    "\n",
    "    def _get_info(self, id, score=None):\n",
    "        \"\"\"Takes an id string and returns the movie info with a url.\"\"\"\n",
    "        try:\n",
    "            info_query = f\"\"\"\n",
    "            SELECT m.primary_title, m.start_year, r.average_rating, r.num_votes\n",
    "            FROM movies m\n",
    "            JOIN ratings r ON m.movie_id = r.movie_id\n",
    "            WHERE m.movie_id = '{id}'\"\"\"\n",
    "            self.cursor_dog.execute(info_query)\n",
    "        except Exception as e:\n",
    "            return tuple([f\"Movie title unknown. ID:{id}\", None, None, None, None, None, id])\n",
    "\n",
    "        t = self.cursor_dog.fetchone()\n",
    "        if t:\n",
    "            title = tuple([t[0], t[1], f\"https://www.imdb.com/title/tt{id}/\", t[2], t[3], score, id])\n",
    "            return title\n",
    "        else:\n",
    "            return tuple([f\"Movie title not retrieved. ID:{id}\", None, None, None, None, None, id])\n",
    "\n",
    "    def get_most_similar_title(self, id, id_list):\n",
    "        \"\"\"Get the title of the most similar movie to id from id_list\"\"\"\n",
    "        clf = self._get_model()\n",
    "        vocab = clf.wv.vocab\n",
    "        if id not in vocab:\n",
    "            return \"\"\n",
    "        id_list = [id for id in id_list if id in vocab] # ensure all in vocab\n",
    "        id_book = self.id_book\n",
    "        match = clf.wv.most_similar_to_given(id, id_list)\n",
    "        return id_book['primaryTitle'].loc[id_book['tconst'] == int(match)].values[0]\n",
    "\n",
    "    def predict(self, input, bad_movies=[], hist_list=[], val_list=[],\n",
    "                ratings_dict = {}, checked_list=[], rejected_list=[],\n",
    "                n=50, harshness=1, rec_movies=True,\n",
    "                show_vibes=False, scoring=False, return_scores=False):\n",
    "        \"\"\"Returns a list of recommendations and useful metadata, given a pretrained\n",
    "        word2vec model and a list of movies.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "            input : iterable\n",
    "                List of movies that the user likes.\n",
    "\n",
    "            bad_movies : iterable\n",
    "                List of movies that the user dislikes.\n",
    "\n",
    "            hist_list : iterable\n",
    "                List of movies the user has seen.\n",
    "\n",
    "            val_list : iterable\n",
    "                List of movies the user has already indicated interest in.\n",
    "                Example: https://letterboxd.com/tabula_rasta/watchlist/\n",
    "                People really load these up over the years, and so they make for \n",
    "                the best validation set we can ask for with current resources.\n",
    "\n",
    "            ratings_dict : dictionary\n",
    "                Dictionary of movie_id keys, user rating values.\n",
    "\n",
    "            checked_list : iterable\n",
    "                List of movies the user likes on the feedback form.\n",
    "\n",
    "            rejected_list : iterable\n",
    "                List of movies the user dislikes on the feedback form.\n",
    "\n",
    "            n : int\n",
    "                Number of recommendations to return.\n",
    "\n",
    "            harshness : int\n",
    "                Weighting to apply to disliked movies.\n",
    "                Ex:\n",
    "                    1 - most strongly account for disliked movies.\n",
    "                    3 - divide \"disliked movies\" vector by 3.\n",
    "\n",
    "            rec_movies : boolean\n",
    "                If False, doesn't return movie recommendations (used for scoring).\n",
    "\n",
    "            show_vibes : boolean\n",
    "                If True, prints out the dupes as a feature.\n",
    "                These movies are closest to the user's taste vector, \n",
    "                indicating some combination of importance and popularity.\n",
    "\n",
    "            scoring : boolean\n",
    "                If True, prints out the validation score.\n",
    "            \n",
    "            return_scores : boolean\n",
    "                If True, skips printing out\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A list of tuples\n",
    "            (Title, Year, IMDb URL, Average Rating, Number of Votes, Similarity score)\n",
    "        \"\"\"\n",
    "\n",
    "        clf = self._get_model()\n",
    "        dupes = []                 # list for storing duplicates for scoring\n",
    "\n",
    "        def _aggregate_vectors(movies, feedback_list=[]):\n",
    "            \"\"\"Gets the vector average of a list of movies.\"\"\"\n",
    "            movie_vec = []\n",
    "            for i in movies:\n",
    "                try:\n",
    "                    m_vec = clf[i]  # get the vector for each movie\n",
    "                    if ratings_dict:\n",
    "                        try:\n",
    "                            r = ratings_dict[i] # get user_rating for each movie\n",
    "                            # Use a polynomial to weight the movie by rating.\n",
    "                            # This equation is somewhat arbitrary. I just fit a polynomial\n",
    "                            # to some weights that look good. The effect is to raise\n",
    "                            # the importance of 1, 2, 9, and 10 star ratings to about 1.8.\n",
    "                            w = ((r**3)*-0.00143) + ((r**2)*0.0533) + (r*-0.4695) + 2.1867\n",
    "                            m_vec = m_vec * w\n",
    "                        except KeyError:\n",
    "                            continue\n",
    "                    movie_vec.append(m_vec)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "            if feedback_list:\n",
    "                for i in feedback_list:\n",
    "                    try:\n",
    "                        f_vec = clf[i]\n",
    "                        movie_vec.append(f_vec*1.8) # weight feedback by changing multiplier here\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "            return np.mean(movie_vec, axis=0)\n",
    "\n",
    "        def _similar_movies(v, bad_movies=[], n=50):\n",
    "            \"\"\"Aggregates movies and finds n vectors with highest cosine similarity.\"\"\"\n",
    "            if bad_movies:\n",
    "                v = _remove_dislikes(bad_movies, v, harshness=harshness)\n",
    "            return clf.similar_by_vector(v, topn= n+1)[1:]\n",
    "\n",
    "        def _remove_dupes(recs, input, bad_movies, hist_list=[], feedback_list=[]):\n",
    "            \"\"\"remove any recommended IDs that were in the input list\"\"\"\n",
    "            all_rated = input + bad_movies + hist_list + feedback_list\n",
    "            nonlocal dupes\n",
    "            dupes = [x for x in recs if x[0] in input]\n",
    "            return [x for x in recs if x[0] not in all_rated]\n",
    "\n",
    "        def _remove_dislikes(bad_movies, good_movies_vec, rejected_list=[], harshness=1):\n",
    "            \"\"\"Takes a list of movies that the user dislikes.\n",
    "            Their embeddings are averaged,\n",
    "            and subtracted from the input.\"\"\"\n",
    "            bad_vec = _aggregate_vectors(bad_movies, rejected_list)\n",
    "            bad_vec = bad_vec / harshness\n",
    "            return good_movies_vec - bad_vec\n",
    "\n",
    "        def _score_model(recs, val_list):\n",
    "            \"\"\"Returns the number of recs that were already in the user's watchlist. Validation!\"\"\"\n",
    "            ids = [x[0] for x in recs]\n",
    "            return len(list(set(ids) & set(val_list)))\n",
    "\n",
    "        aggregated = _aggregate_vectors(input, checked_list)\n",
    "        recs = _similar_movies(aggregated, bad_movies, n=n)\n",
    "        recs = _remove_dupes(recs, input, bad_movies, hist_list, checked_list + rejected_list)\n",
    "        formatted_recs = [self._get_info(x[0], x[1]) for x in recs]\n",
    "        if val_list:\n",
    "            if return_scores:\n",
    "                return tuple([_score_model(recs, val_list), sum([i[3] for i in formatted_recs if i[3] is not None])/len(formatted_recs)])\n",
    "            elif scoring:\n",
    "                print(f\"The model recommended {_score_model(recs, val_list)} movies that were on the watchlist!\\n\")\n",
    "                print(f\"\\t\\t Average Rating: {sum([i[3] for i in formatted_recs if i[3] is not None])/len(formatted_recs)}\\n\")\n",
    "        if show_vibes:\n",
    "            print(\"You'll get along with people who like: \\n\")\n",
    "            for x in dupes:\n",
    "                print(self._get_info(x[0], x[1]))\n",
    "            print('\\n')\n",
    "        if rec_movies:\n",
    "            return formatted_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "tewwzvajQyW3",
    "outputId": "fecfd0cb-c9bd-45c3-e7a0-cff6d0e1f52b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.3, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\users\\ryloid\\appdata\\roaming\\python\\python37\\site-packages\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ················\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    }
   ],
   "source": [
    "! pip3 install psycopg2-binary --user\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "from getpass import getpass\n",
    "\n",
    "# connect to database. Never save your password to a notebook.\n",
    "connection = psycopg2.connect(\n",
    "    database  = \"postgres\",\n",
    "    user      = \"postgres\",\n",
    "    password  = getpass(), # secure password entry. Enter DB password in the prompt and press Enter.\n",
    "    host      = \"\",\n",
    "    port      = '5432'\n",
    ")\n",
    "\n",
    "# create cursor that is used throughout\n",
    "try:\n",
    "    c = connection.cursor()\n",
    "    print(\"Connected!\")\n",
    "except Exception as e:\n",
    "    print(\"Connection problem chief!\\n\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OuJQ6tNHZaOP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tconst            int64\n",
       "primaryTitle     object\n",
       "originalTitle    object\n",
       "startYear         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get ratings data from DB\n",
    "from pandas import DataFrame\n",
    "\n",
    "userid_temp = 1111\n",
    "\n",
    "c.execute(f\"SELECT * FROM test_ratings WHERE userid={userid_temp};\")\n",
    "ratings_sql= c.fetchall()\n",
    "ratings = DataFrame(ratings_sql, columns = ['Date', 'Name', 'Year', 'Letterboxd_URI', 'Rating', 'userid'])\n",
    "ratings= ratings.dropna()\n",
    "ratings.astype({'Year': 'int64'}).dtypes\n",
    "\n",
    "c.execute(f\"SELECT * FROM test_watchlist WHERE userid={userid_temp};\")\n",
    "watchlist_sql= c.fetchall()\n",
    "watchlist = DataFrame(watchlist_sql, columns = ['Date', 'Name', 'Year', 'Letterboxd_URI', 'userid'])\n",
    "watchlist = watchlist.dropna()\n",
    "watchlist.astype({'Year': 'int64'}).dtypes\n",
    "\n",
    "c.execute(f\"SELECT * FROM test_watched WHERE userid={userid_temp};\")\n",
    "watched_sql= c.fetchall()\n",
    "watched = DataFrame(watched_sql, columns = ['Date', 'Name', 'Year', 'Letterboxd_URI', 'userid'])\n",
    "watched = watched.dropna()\n",
    "watched.astype({'Year': 'int64'}).dtypes\n",
    "\n",
    "c.execute(\"SELECT * FROM test_title_basics_small;\")\n",
    "title_basics_small_sql= c.fetchall()\n",
    "id_book = DataFrame(title_basics_small_sql, columns = ['tconst', 'primaryTitle', 'originalTitle', 'startYear'])\n",
    "id_book = id_book.dropna()\n",
    "id_book.astype({'startYear': 'int64'}).dtypes\n",
    "\n",
    "# note: if you import IMDb data, it's currently encoded 'cp1252' (but they may someday switch to utf-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Letterboxd_URI</th>\n",
       "      <th>Rating</th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>Psycho</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>https://letterboxd.com/film/psycho/</td>\n",
       "      <td>5</td>\n",
       "      <td>1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-05-03</td>\n",
       "      <td>ABE</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>https://letterboxd.com/film/abe/</td>\n",
       "      <td>3</td>\n",
       "      <td>1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-09-20</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>https://letterboxd.com/film/pulp-fiction/</td>\n",
       "      <td>5</td>\n",
       "      <td>1111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date          Name    Year  \\\n",
       "0  2013-02-11        Psycho  1960.0   \n",
       "1  2013-05-03           ABE  2013.0   \n",
       "2  2012-09-20  Pulp Fiction  1994.0   \n",
       "\n",
       "                              Letterboxd_URI  Rating  userid  \n",
       "0        https://letterboxd.com/film/psycho/       5    1111  \n",
       "1           https://letterboxd.com/film/abe/       3    1111  \n",
       "2  https://letterboxd.com/film/pulp-fiction/       5    1111  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Letterboxd_URI</th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Name, Year, Letterboxd_URI, userid]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watchlist[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Letterboxd_URI</th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Name, Year, Letterboxd_URI, userid]\n",
       "Index: []"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305342, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_book.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rSwD8bVJxrG6"
   },
   "outputs": [],
   "source": [
    "# prep user data\n",
    "good_list, bad_list, hist_list, val_list, ratings_dict = prep_data(\n",
    "                                    ratings, watchlist_df=watchlist, watched_df=watched, good_threshold=4, bad_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "M0Q3K8mdQkb8",
    "outputId": "dbf0bfb3-58b4-4bbd-d5fc-0c94377ca225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model recommended 24 movies that were on the watchlist!\n",
      "\n",
      "\t\t Average Rating: 7.951162790697674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = Recommender('models/w2v_limitingfactor_v3.51.model')\n",
    "s.predict(good_list, bad_list, hist_list, val_list, ratings_dict, n=100, harshness=1, rec_movies=False, scoring=True,)\n",
    "# s.predict(aj2, n=100, harshness=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model recommended 3 movies that were on the watchlist!\n",
      "\n",
      "\t\t Average Rating: 8.25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = s.predict(good_list, bad_list, hist_list, val_list, ratings_dict, n=20, harshness=1, rec_movies=True, scoring=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('On the Waterfront',\n",
       "  1954,\n",
       "  'https://www.imdb.com/title/tt0047296/',\n",
       "  8.1,\n",
       "  132973,\n",
       "  0.5372891426086426,\n",
       "  '0047296'),\n",
       " ('Pather Panchali',\n",
       "  1955,\n",
       "  'https://www.imdb.com/title/tt0048473/',\n",
       "  8.6,\n",
       "  20230,\n",
       "  0.5281749963760376,\n",
       "  '0048473'),\n",
       " ('Sunset Blvd.',\n",
       "  1950,\n",
       "  'https://www.imdb.com/title/tt0043014/',\n",
       "  8.4,\n",
       "  186742,\n",
       "  0.5182325839996338,\n",
       "  '0043014'),\n",
       " ('Do the Right Thing',\n",
       "  1989,\n",
       "  'https://www.imdb.com/title/tt0097216/',\n",
       "  7.9,\n",
       "  78577,\n",
       "  0.5149610042572021,\n",
       "  '0097216')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9159791634"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "random.randint(1, 10000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "0220.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
