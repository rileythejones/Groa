{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json \n",
    "from datetime import datetime\n",
    "import random\n",
    "import hashlib\n",
    "import pandas as pd \n",
    "from recommender import Recommender\n",
    "from helpers import fill_id, df_to_id_list, prep_data\n",
    "\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class PythonPredictor:\n",
    "    def __init__(self, config={}):\n",
    "        \"\"\" Requires configuration from cortex.yaml \"\"\"\n",
    "         \n",
    "        # When using s3 bucket to download the model\n",
    "        # s3 = boto3.client(\"s3\")\n",
    "        # s3.download_file(config[\"bucket\"], config[\"key\"], \"w2v_limitingfactor_v3.51.model\")\n",
    "\n",
    "        self.model = Recommender('models/w2v_limitingfactor_v3.51.model')\n",
    "\n",
    "        pass\n",
    "\n",
    "    def predict(self, payload): # recieves userid, outputs recommendation_id\n",
    "        \"\"\"Called once per request. Runs preprocessing of the request payload, inference, and postprocessing of the inference output. Required.\n",
    "\n",
    "        Args:\n",
    "            payload: The parsed JSON request payload.\n",
    "\n",
    "        Returns:\n",
    "            Prediction or a batch of predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.connect_db()\n",
    "        user_id = payload\n",
    "        \n",
    "        \"\"\" testing with local letterboxd data \"\"\"\n",
    "        \n",
    "#         ratings = pd.read_csv('exported_data/imdb/riley_imdb_ratings.csv', engine='python')\n",
    "#         ratings = pd.read_csv('exported_data/letterboxd/riley/ratings.csv',  engine='python')\n",
    "        \n",
    "    \n",
    "        query = \"SELECT EXISTS(SELECT 1 FROM user_letterboxd_ratings where user_id=%s);\" \n",
    "        self.model.cursor_dog.execute(query, (user_id,))\n",
    "        boolean = self.model.cursor_dog.fetchall()\n",
    "        \n",
    "        if boolean[0][0]==False: # True\n",
    "            self.model.cursor_dog.close()\n",
    "            self.model.connection.close()\n",
    "            return \"user_id not found\"\n",
    "    \n",
    "    \n",
    "        self.model.cursor_dog.execute(\"SELECT date, name, year, letterboxd_uri, rating FROM user_letterboxd_ratings WHERE user_id=%s;\", (user_id,))\n",
    "        ratings_sql= self.model.cursor_dog.fetchall()\n",
    "        ratings = pd.DataFrame(ratings_sql, columns = ['Date', 'Name', 'Year', 'Letterboxd URI', 'Rating'])\n",
    "        ratings= ratings.dropna()\n",
    "        \n",
    "\n",
    "#         self.model.cursor_dog.execute(\"SELECT * FROM test_watchlist WHERE user_id=%s;\", (user_id,))\n",
    "#         watchlist_sql= self.model.cursor_dog.fetchall()\n",
    "#         watchlist = pd.DataFrame(watchlist_sql, columns = ['Date', 'Name', 'Year', 'Letterboxd URI', 'user_id'])\n",
    "#         watchlist = watchlist.dropna()\n",
    "        \n",
    "\n",
    "#         self.model.cursor_dog.execute(\"SELECT * FROM test_watched WHERE user_id=%s;\", (user_id,))\n",
    "#         watched_sql= self.model.cursor_dog.fetchall()\n",
    "#         watched = pd.DataFrame(watched_sql, columns = ['Date', 'Name', 'Year', 'Letterboxd URI', 'user_id'])\n",
    "#         watched = watched.dropna()\n",
    "        \n",
    "\n",
    "#         self.model.cursor_dog.execute(\"SELECT * FROM test_title_basics_small;\")\n",
    "#         title_basics_small_sql= self.model.cursor_dog.fetchall()\n",
    "#         id_book = pd.DataFrame(title_basics_small_sql, columns = ['tconst', 'primaryTitle', 'originalTitle', 'startYear'])\n",
    "#         id_book = id_book.dropna()\n",
    "        \n",
    "        \"\"\" Prepare data  \"\"\"\n",
    "        good_list, bad_list, hist_list, val_list, ratings_dict = prep_data(\n",
    "                                    ratings, watched_df=None, watchlist_df=None, good_threshold=3, bad_threshold=2) \n",
    "        \n",
    "        \"\"\" Load JSON into a list (if applicable) \"\"\" \n",
    "        # payload_jsonified = json.dumps(payload)\n",
    "        # movie_dict = json.loads(payload_jsonified)\n",
    "        # movie_list = list(movie_dict.values())\n",
    "        \n",
    "        \"\"\" Run prediction with parameters \"\"\"\n",
    "        \n",
    "        predictions = self.model.predict(good_list, bad_list, hist_list, val_list, ratings_dict, n=20, harshness=4, rec_movies=True, scoring=True,)\n",
    "        \n",
    "        \"\"\" Turn predictions into JSON \"\"\"\n",
    "        \n",
    "        names = ['Title', 'Year', 'IMDB URL', 'Average Rating', 'Number of Votes', 'Similarity Score', 'IMDB ID']\n",
    "        names_lists = {key:[] for key in names}\n",
    "        \n",
    "        for x in range(0, len(predictions[0])):\n",
    "            for y in range(0, len(predictions)):\n",
    "                names_lists[names[x]].append(predictions[y][x])\n",
    "                \n",
    "        results_dict = [dict(zip(names_lists,t)) for t in zip(*names_lists.values())]\n",
    "        recommendation_json = json.dumps(results_dict)\n",
    "        \n",
    "        \n",
    "        \"\"\" Commit to the database \"\"\"\n",
    "        \n",
    "        string_json = str(recommendation_json)\n",
    "        hash_object = hashlib.md5(string_json.encode('ascii'))\n",
    "        recommendation_id = hash_object.hexdigest()\n",
    "        \n",
    "        query = \"SELECT EXISTS(SELECT 1 FROM recommendations where recommendation_id=%s);\" \n",
    "        self.model.cursor_dog.execute(query, (recommendation_id,))\n",
    "        boolean = self.model.cursor_dog.fetchall()\n",
    "        date = datetime.now()\n",
    "        \n",
    "        if boolean[0][0]: # True\n",
    "            self.model.cursor_dog.close()\n",
    "            self.model.connection.close()\n",
    "            return \"Already recommended\", recommendation_json\n",
    "        else:\n",
    "            query = \"INSERT INTO recommendations(user_id, recommendation_id, recommendation_json, date) VALUES (%s, %s, %s, %s);\"\n",
    "            self.model.cursor_dog.execute(query, (user_id, recommendation_id, recommendation_json, date))\n",
    "            self.model.connection.commit()\n",
    "            self.model.cursor_dog.close()\n",
    "            self.model.connection.close()\n",
    "            return \"Recommendation committed to DB with id:\", recommendation_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = PythonPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'user_id not found'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(1111) # works with letterboxd , can change code to with with imdb but results are weird, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groa (Python3.7)",
   "language": "python",
   "name": "groa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
