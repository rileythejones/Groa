{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and deploy the docker container\n",
    "Ensure this notebook is running above the \"container\" folder containing the dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  45.31MB\n",
      "Step 1/16 : FROM ubuntu:16.04\n",
      " ---> 96da9143fb18\n",
      "Step 2/16 : MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      " ---> Using cache\n",
      " ---> 3c855fe9d05f\n",
      "Step 3/16 : RUN apt-get update -y\n",
      " ---> Using cache\n",
      " ---> f0afc96dc1a2\n",
      "Step 4/16 : RUN apt-get install -y software-properties-common\n",
      " ---> Using cache\n",
      " ---> d2a5e67d7e6f\n",
      "Step 5/16 : RUN add-apt-repository -y ppa:deadsnakes/ppa\n",
      " ---> Using cache\n",
      " ---> 1e5d0bb4cddb\n",
      "Step 6/16 : RUN apt-get update -y\n",
      " ---> Using cache\n",
      " ---> d53f9eae657a\n",
      "Step 7/16 : RUN apt-get install -y python3.6\n",
      " ---> Using cache\n",
      " ---> 017621eb6bd1\n",
      "Step 8/16 : RUN ln -s /usr/bin/python3.6 /usr/bin/python\n",
      " ---> Using cache\n",
      " ---> b9fa41b93dae\n",
      "Step 9/16 : RUN python3 -V\n",
      " ---> Using cache\n",
      " ---> 350bb849f651\n",
      "Step 10/16 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> f375d7448a5f\n",
      "Step 11/16 : RUN wget https://bootstrap.pypa.io/get-pip.py && python3 get-pip.py &&     pip3 install numpy==1.16.2 scipy==1.2.1 scikit-learn==0.20.2 gensim==3.8.1 pandas flask gevent gunicorn\n",
      " ---> Using cache\n",
      " ---> 285e5b39827f\n",
      "Step 12/16 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 09821f1939e8\n",
      "Step 13/16 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 436ae0a4df46\n",
      "Step 14/16 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 19fc8bc2bfc9\n",
      "Step 15/16 : COPY decision_trees /opt/program\n",
      " ---> 4bbf9ae25bed\n",
      "Step 16/16 : WORKDIR /opt/program\n",
      " ---> Running in 8f14856d60a7\n",
      "Removing intermediate container 8f14856d60a7\n",
      " ---> cdda36574158\n",
      "Successfully built cdda36574158\n",
      "Successfully tagged sagemaker-word2vec:latest\n",
      "The push refers to repository [639634733305.dkr.ecr.us-east-1.amazonaws.com/sagemaker-word2vec]\n",
      "94d553f29ddf: Preparing\n",
      "05b745ea1bdd: Preparing\n",
      "abcd6b435245: Preparing\n",
      "0ecdcd66dfcc: Preparing\n",
      "2b1bf3774962: Preparing\n",
      "5b21fa099f90: Preparing\n",
      "3a0e7d0a8465: Preparing\n",
      "92503c2cb892: Preparing\n",
      "7210bec23e77: Preparing\n",
      "fa1693d66d0b: Preparing\n",
      "293b479c17a5: Preparing\n",
      "bd95983a8d99: Preparing\n",
      "96eda0f553ba: Preparing\n",
      "5b21fa099f90: Waiting\n",
      "3a0e7d0a8465: Waiting\n",
      "92503c2cb892: Waiting\n",
      "7210bec23e77: Waiting\n",
      "fa1693d66d0b: Waiting\n",
      "293b479c17a5: Waiting\n",
      "bd95983a8d99: Waiting\n",
      "96eda0f553ba: Waiting\n",
      "05b745ea1bdd: Layer already exists\n",
      "2b1bf3774962: Layer already exists\n",
      "abcd6b435245: Layer already exists\n",
      "0ecdcd66dfcc: Layer already exists\n",
      "5b21fa099f90: Layer already exists\n",
      "3a0e7d0a8465: Layer already exists\n",
      "92503c2cb892: Layer already exists\n",
      "7210bec23e77: Layer already exists\n",
      "fa1693d66d0b: Layer already exists\n",
      "96eda0f553ba: Layer already exists\n",
      "293b479c17a5: Layer already exists\n",
      "bd95983a8d99: Layer already exists\n",
      "94d553f29ddf: Pushed\n",
      "latest: digest: sha256:7f2aa8fceb6f913387d08000f6b420eff244849a183bba143aaa623f579e9995 size: 3042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-word2vec\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x decision_trees/train\n",
    "chmod +x decision_trees/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-1 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = 'word2vec'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-639634733305/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.session import Session\n",
    "\n",
    "model_data = Session().upload_data(path='model.tar.gz', key_prefix='model')\n",
    "print(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the image path\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-word2vec:latest'.format(account, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to deploy the model, you need to have the model created based on your model artifacts, \n",
    "# create an endpoint configuration and then create the endpoint based on the two.\n",
    "# first let's create the model\n",
    "\n",
    "client = boto3.client('sagemaker')\n",
    "ModelName='TestCx-BYOA' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "first_model = client.create_model(\n",
    "    ModelName=ModelName,\n",
    "    PrimaryContainer={\n",
    "        'Image': image,\n",
    "        'ModelDataUrl': 's3://sagemaker-us-east-1-639634733305/model/model.tar.gz'    # note that the model.tar.gz file is a tarball of our word2vec_2.model file\n",
    "        },\n",
    "    ExecutionRoleArn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestCx-BYOA-2020-01-22-22-09-54\n",
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-1:639634733305:endpoint-config/testcx-byoa-2020-01-22-22-09-54\n"
     ]
    }
   ],
   "source": [
    "# create the endpoint configuration\n",
    "endpoint_config_name = 'TestCx-BYOA-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m4.xlarge',\n",
    "        'InitialVariantWeight':1,\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':ModelName,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestCx-BYOA-2020-01-22-22-09-54\n",
      "arn:aws:sagemaker:us-east-1:639634733305:endpoint/testcx-byoa-2020-01-22-22-09-54\n"
     ]
    }
   ],
   "source": [
    "# create the endpoint\n",
    "endpoint_name = 'TestCx-BYOA-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer, csv_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import RealTimePredictor\n",
    "\n",
    "predictor = RealTimePredictor(endpoint = endpoint_name, sagemaker_session=sess, serializer=csv_serializer, deserializer=csv_deserializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(first_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "coen_bros = \"0116282,2042568,1019452,1403865,190590,138524,335245,477348,887883,101410\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predictions(arr_input, batch_size):\n",
    "    predictions=[]\n",
    "    \n",
    "    if type(arr_input) != np.ndarray:\n",
    "        arr_input = np.array(arr_input)\n",
    "        \n",
    "    for arr in np.array_split(arr_input, batch_size):\n",
    "        if arr.size > 0:\n",
    "            print(\"Shape:{0}\".format(arr.shape))\n",
    "            resule = predictor.predict(arr)\n",
    "            result = result.decode(\"utf-8\")\n",
    "            result = result.split(',')\n",
    "            predictions += [np.expm1(float(r)) for r in result]\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.DataFrame(data=['116282', '2042568', '1019452', '1403865', \n",
    "                                        '190590', '138524', '335245', '477348', \n",
    "                                        '887883', '101410'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"('970922', 0.9125374555587769)\"], [\"('1121964', 0.9035829305648804)\"], [\"('468442', 0.8992078900337219)\"], [\"('1326954', 0.8989676237106323)\"], [\"('353671', 0.898465633392334)\"], [\"('1328913', 0.8974928855895996)\"], [\"('925259', 0.8972901701927185)\"]]\n"
     ]
    }
   ],
   "source": [
    "print(predictor.predict(coen_bros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.DataFrame(data=['116282', '2042568', '1019452', '1403865', \n",
    "                                        '190590', '138524', '335245', '477348', \n",
    "                                        '887883', '101410'])\n",
    "test_input = ['116282', '2042568', '1019452', \n",
    "             '1403865', '190590', '138524', \n",
    "             '335245', '477348', '887883', '101410']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[0] = test_df[0].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[str(x) for x in lst] for lst in test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = open('./data/word2vec_test_data.csv', \"r+\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = RealTimePredictor(endpoint = \"TestCx-BYOA-2020-01-21-22-14-57\", sagemaker_session=sess, serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['movieid']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(int, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_json()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
