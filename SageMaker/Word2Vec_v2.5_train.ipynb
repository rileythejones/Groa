{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec v2.5: \"Mistake Not\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3001,
     "status": "ok",
     "timestamp": 1578954025043,
     "user": {
      "displayName": "Cooper Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCBd8BZPrGsSITPUox_UKbSmoT6f0h8PucNwTr60w=s64",
      "userId": "15095415326628117346"
     },
     "user_tz": 300
    },
    "id": "iQWJUpFjdlyj",
    "outputId": "f44ae211-ffec-4beb-930f-24240491e14d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /home/ec2-user/.local/lib/python3.6/site-packages (2.8.4)\n",
      "\u001b[33mYou are using pip version 19.0.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install psycopg2-binary --user\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5789,
     "status": "ok",
     "timestamp": 1578954032020,
     "user": {
      "displayName": "Cooper Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCBd8BZPrGsSITPUox_UKbSmoT6f0h8PucNwTr60w=s64",
      "userId": "15095415326628117346"
     },
     "user_tz": 300
    },
    "id": "at19RYvtdlyw",
    "outputId": "0be27d51-9199-483a-f79d-635dcb902f35"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ················\n"
     ]
    }
   ],
   "source": [
    "# connect to database\n",
    "connection = psycopg2.connect(\n",
    "    database  = \"postgres\",\n",
    "    user      = \"postgres\",\n",
    "    password  = getpass(),\n",
    "    host      = \"movie-rec-scrape.cvslmiksgnix.us-east-1.rds.amazonaws.com\",\n",
    "    port      = '5432'\n",
    ")\n",
    "# Enter database password below and press Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2765,
     "status": "ok",
     "timestamp": 1578955267613,
     "user": {
      "displayName": "Cooper Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCBd8BZPrGsSITPUox_UKbSmoT6f0h8PucNwTr60w=s64",
      "userId": "15095415326628117346"
     },
     "user_tz": 300
    },
    "id": "d417YjdVdly9",
    "outputId": "bc2f5955-c858-40ca-8e71-f0e3d2410afd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    }
   ],
   "source": [
    "# create cursor that is used throughout\n",
    "try:\n",
    "    c = connection.cursor()\n",
    "    print(\"Connected!\")\n",
    "except:\n",
    "    print(\"Connection problem chief!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data and train.\n",
    "1. Get the list of reviewers whose reviews we want (about 17k)\n",
    "2. Get the dataframe of reviewers, movie IDs with positive reviews\n",
    "3. Inner join the above two dataframes.\n",
    "4. Run the list constructor on the join table to construct the training data.\n",
    "    - Training data is of this format: [['movieid1', 'movieid2', ...], ...]\n",
    "5. Train Word2Vec on the list of watch histories (which are themselves lists of movie IDs).\n",
    "6. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfmu_UdndlzG"
   },
   "outputs": [],
   "source": [
    "# Get reviewers with at least 10 positive reviews (rating 7-10 inclusive)\n",
    "c.execute(\"\"\"\n",
    "select username\n",
    "from reviews\n",
    "where user_rating between 7 and 10\n",
    "group by username\n",
    "having count(username) >= 10\n",
    "order by count(username) desc\n",
    "\"\"\")\n",
    "\n",
    "reviewers = c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8A_os2zUdlzQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5493944</td>\n",
       "      <td>dmldc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0095016</td>\n",
       "      <td>immortal_saint1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5493944</td>\n",
       "      <td>vampyr_vashti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5493944</td>\n",
       "      <td>julieclowes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5493944</td>\n",
       "      <td>stephgonser</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieid           userid\n",
       "0  5493944            dmldc\n",
       "1  0095016  immortal_saint1\n",
       "2  5493944    vampyr_vashti\n",
       "3  5493944      julieclowes\n",
       "4  5493944      stephgonser"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get positive reviews from database\n",
    "c.execute(\"SELECT movie_id, username FROM reviews WHERE user_rating > 6\")\n",
    "result = c.fetchall()\n",
    "\n",
    "# create reviews dataframe\n",
    "df = pd.DataFrame(result, columns = ['movieid', 'userid'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6880,
     "status": "ok",
     "timestamp": 1578955272419,
     "user": {
      "displayName": "Cooper Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCBd8BZPrGsSITPUox_UKbSmoT6f0h8PucNwTr60w=s64",
      "userId": "15095415326628117346"
     },
     "user_tz": 300
    },
    "id": "_47oo4s1dlzY",
    "outputId": "9f3542e2-2648-445d-a601-18820c9d9723"
   },
   "outputs": [],
   "source": [
    "# create reviewers dataframe\n",
    "df_reviewers = pd.DataFrame(reviewers, columns = ['userid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(904140, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge to get only the IDs relevant to training\n",
    "df = df.merge(df_reviewers, how='inner', on='userid')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3472,
     "status": "ok",
     "timestamp": 1578955409541,
     "user": {
      "displayName": "Cooper Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCBd8BZPrGsSITPUox_UKbSmoT6f0h8PucNwTr60w=s64",
      "userId": "15095415326628117346"
     },
     "user_tz": 300
    },
    "id": "z2OBA-xqdl0m",
    "outputId": "faa65cc8-cd3d-4f08-fb57-5099851a509c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded plugins: dkms-build-requires, priorities, update-motd, upgrade-helper,\n",
      "              : versionlock\n",
      "You need to be root to perform this command.\n",
      "Loaded plugins: dkms-build-requires, priorities, update-motd, upgrade-helper,\n",
      "              : versionlock\n",
      "You need to be root to perform this command.\n",
      "Python 3.6.5 :: Anaconda, Inc.\n"
     ]
    }
   ],
   "source": [
    "# ! sudo su\n",
    "# ! yum update -y\n",
    "# ! yum -y install python-pip\n",
    "# ! python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3298,
     "status": "ok",
     "timestamp": 1578955411283,
     "user": {
      "displayName": "Cooper Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCBd8BZPrGsSITPUox_UKbSmoT6f0h8PucNwTr60w=s64",
      "userId": "15095415326628117346"
     },
     "user_tz": 300
    },
    "id": "a8DITE9wdl0q",
    "outputId": "79c68333-c722-48a2-ee72-49aa5f1c7a15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/bin/pip\n"
     ]
    }
   ],
   "source": [
    "# ! which pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (4.41.1)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: gensim in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (3.8.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (1.14.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (1.1.0)\n",
      "Requirement already satisfied: boto>=2.32 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.48.0)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (1.10.19)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.20.0)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.13.19)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (1.23)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2.6)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.19->boto3->smart-open>=1.8.1->gensim) (2.7.3)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.19->boto3->smart-open>=1.8.1->gensim) (0.14)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install tqdm\n",
    "# ! python -c 'import tqdm'\n",
    "! python -m pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13545,
     "status": "ok",
     "timestamp": 1578955421790,
     "user": {
      "displayName": "Cooper Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCBd8BZPrGsSITPUox_UKbSmoT6f0h8PucNwTr60w=s64",
      "userId": "15095415326628117346"
     },
     "user_tz": 300
    },
    "id": "ZvEmewUhdl05",
    "outputId": "3e8068d2-0604-4d06-9dc0-47989994f120"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "smscgWxjdl0_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17812/17812 [44:07<00:00,  6.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17812"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list to capture watch history of the users\n",
    "watched_train = []\n",
    "\n",
    "# populate the list with the movie codes\n",
    "for i in tqdm(reviewers):\n",
    "    temp = df[df[\"userid\"] == i[0]][\"movieid\"].tolist()\n",
    "    watched_train.append(temp)\n",
    "    \n",
    "len(watched_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model for later\n",
    "import pickle\n",
    "pickle.dump(watched_train, open('watched_train.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save the model in protocol 2 so it can be opened in python 2.7\n",
    "# import pickle\n",
    "# temp = pickle.load(open('watched_train.sav', 'rb'))\n",
    "# pickle.dump(temp, open('watched_train.sav', 'wb'), protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "**Important:** The previous model was trained on movie IDs that were inside lists of length 1, with watch histories being lists of lists.\n",
    "\n",
    "This model eschews the inner lists. Each watch history is simply a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdGxB2_gdl1S",
    "outputId": "b367f0ff-8e54-4c9b-dba5-fd3287d4e413"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8222420, 9041400)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train word2vec model\n",
    "model = Word2Vec(window = 10, sg = 1, hs = 0,\n",
    "                 negative = 10, # for negative sampling\n",
    "                 alpha=0.03, min_alpha=0.0007,\n",
    "                 seed = 14)\n",
    "\n",
    "model.build_vocab(watched_train, progress_per=200)\n",
    "\n",
    "model.train(watched_train, total_examples = model.corpus_count, \n",
    "            epochs=10, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-sWPKYgTdl1W"
   },
   "outputs": [],
   "source": [
    "# save word2vec model\n",
    "model.save(\"w2v_mistakenot.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vSeGqA97dl1Z"
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "import gensim\n",
    "model = gensim.models.Word2Vec.load(\"w2v_mistakenot.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFH5khHrdl1d"
   },
   "outputs": [],
   "source": [
    "# prunes the model, making it faster but unable to train any more.\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jsHJnjXtdl1g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=24784, size=100, alpha=0.03)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "izJD5tDVdl1k",
    "outputId": "e628d91e-1b25-46d6-923b-e4004a0050e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24784, 100)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all vectors\n",
    "X = model[model.wv.vocab]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs are words in the model, and callable as such.\n",
    "# model['0110912']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_title(id):\n",
    "#     \"\"\"Takes an id string and returns the movie title.\"\"\"\n",
    "    \n",
    "#     try:\n",
    "#         c.execute(f\"\"\"\n",
    "#         select primary_title, start_year\n",
    "#         from movies\n",
    "#         where movie_id = '{id}'\"\"\")\n",
    "#     except:\n",
    "#         return f\"Movie title unknown. ID:{id}\"\n",
    "    \n",
    "#     t = c.fetchone()\n",
    "#     title = tuple([t[0], t[1], f\"https://www.imdb.com/title/tt{id}/\"])\n",
    "#     return title\n",
    "    \n",
    "# def predict(model, input, num_recs=6):\n",
    "#         \"\"\"For the input, do the predictions and return them.\n",
    "\n",
    "#         Args:\n",
    "#             model: the word2vec model object.\n",
    "#             input: a list of movie IDs.\n",
    "#             num_recs: the number of recommendations to return.\n",
    "#         \"\"\"\n",
    "\n",
    "#         def _aggregate_vectors(movies):\n",
    "#             # get the vector average of the movies in the input.\n",
    "#             # discard unrecognized IDs.\n",
    "#             movie_vec = []\n",
    "#             for i in movies:\n",
    "#                 try:\n",
    "#                     movie_vec.append(model[i])\n",
    "#                 except KeyError:\n",
    "#                     continue\n",
    "#             return np.mean(movie_vec, axis=0)\n",
    "\n",
    "#         def _similar_movies(v, n):\n",
    "#             # extract most similar movies for the input vector\n",
    "#             return model.similar_by_vector(v, topn= n+1)[1:]\n",
    "        \n",
    "#         def _remove_dupes(recs):\n",
    "#             # remove any recommendations that were in the input\n",
    "#             return [x for x in recs if x not in input]\n",
    "        \n",
    "        \n",
    "        \n",
    "#         # aggregate input and find similar vectors.\n",
    "#         recs = _similar_movies(_aggregate_vectors(input), num_recs)\n",
    "#         # get titles\n",
    "#         recs = [get_title(y[0]) for y in recs] \n",
    "#         return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ratings = pd.read_csv('ratings.csv') # import my Letterboxd ratings\n",
    "ratings.head()\n",
    "ratings = ratings.dropna(axis=0, subset=['Rating', 'Name', 'Year'])\n",
    "\n",
    "# set threshold for minimum \"good\" rating\n",
    "threshold = 3.5\n",
    "good = ratings[ratings['Rating'] >= threshold]\n",
    "bad = ratings[ratings['Rating'] < threshold]\n",
    "\n",
    "def df_to_id_list(df):\n",
    "    \"\"\"\n",
    "    Input: dataframe of movies from my ratings.csv Letterboxd export\n",
    "    \n",
    "    Output: List of the IDs for those movies, ready for inferencing.\n",
    "    \"\"\"\n",
    "    ids = []\n",
    "    names = df.Name.tolist()\n",
    "    names = [x.replace(\"'\", \"\") for x in names]\n",
    "    years = df.Year.tolist()\n",
    "    years = [int(year) for year in years]\n",
    "    info = list(zip(names, years))\n",
    "    for i, j in info:\n",
    "        try:\n",
    "            c.execute(f\"\"\"\n",
    "                SELECT movie_id\n",
    "                FROM movies\n",
    "                WHERE primary_title LIKE '{i}' AND start_year = {j}\n",
    "                ORDER BY runtime_minutes DESC\n",
    "                LIMIT 1\"\"\")\n",
    "            id = c.fetchone()[0]\n",
    "            ids.append(id)\n",
    "        except:\n",
    "            continue\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 175\n"
     ]
    }
   ],
   "source": [
    "good_list = df_to_id_list(good)\n",
    "bad_list = df_to_id_list(bad)\n",
    "print(len(good_list), len(bad_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0084345'"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "test_me = 'https://www.imdb.com/title/tt0084345/'\n",
    "test_me.split(\"/tt\")[1][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringService(object):\n",
    "    model = None                # Where we keep the model when it's loaded\n",
    "\n",
    "    @classmethod\n",
    "    def get_model(cls):\n",
    "        \"\"\"Get the model object for this instance, loading it if it's not already loaded.\"\"\"\n",
    "        if cls.model == None:\n",
    "            # load the gensim model\n",
    "            w2v_model = gensim.models.Word2Vec.load(\"w2v_mistakenot.model\")\n",
    "            # keep only the normalized vectors.\n",
    "            # This saves memory but makes the model untrainable (read-only).\n",
    "            w2v_model.init_sims(replace=True)\n",
    "            # with open(os.path.join(model_path, 'decision-tree-model.pkl'), 'r') as inp:\n",
    "            #     cls.model = pickle.load(inp)\n",
    "            cls.model = w2v_model\n",
    "        return cls.model\n",
    "\n",
    "    @classmethod\n",
    "    def predict(cls, input, bad_movies=[], n=20, harshness=1):\n",
    "        \"\"\"Returns a list of recommendations and useful metadata, given a pretrained \n",
    "        word2vec model and a list of movies.\n",
    "\n",
    "        Args:\n",
    "            cls (.model object): The pretrained word2vec model.\n",
    "            \n",
    "            input (list of strings): The list of movies that the user likes.\n",
    "            \n",
    "            bad_movies (list of strings): The list of movies that the user dislikes.\n",
    "            \n",
    "            n (int): The number of recommendations to return.\n",
    "            \n",
    "        Output: A list of tuples: Title, Year, IMDb URL, Similarity score.\n",
    "        \"\"\"\n",
    "        \n",
    "        # get pretrained model\n",
    "        clf = cls.get_model()\n",
    "\n",
    "        def _aggregate_vectors(movies):\n",
    "            \"\"\"Gets the vector average of a list of movies.\"\"\"\n",
    "            movie_vec = []\n",
    "            for i in movies:\n",
    "                try:\n",
    "                    movie_vec.append(clf[i]) # get the vector for each movie\n",
    "                except KeyError:\n",
    "                    continue\n",
    "            return np.mean(movie_vec, axis=0)\n",
    "\n",
    "        def _similar_movies(v, bad_movies=[], n = 10):\n",
    "            \"\"\"Takes aggregated vector of good movies, \n",
    "            and optionally, a list of disliked movies.\n",
    "            Subtracts disliked movies.\n",
    "            Returns most similar movies for the input vector\n",
    "            \n",
    "            n: number of recommendations to return.\"\"\"\n",
    "            if bad_movies:\n",
    "                v = _remove_dislikes(bad_movies, v, input=input, harshness=harshness)\n",
    "            return clf.similar_by_vector(v, topn= n+1)[1:]\n",
    "            \n",
    "        def _remove_dupes(recs, input, bad_movies):\n",
    "            \"\"\"remove any recommended IDs that were in the input list\"\"\"\n",
    "            all_seen = input + bad_movies\n",
    "            return [x for x in recs if x[0] not in all_seen]\n",
    "\n",
    "        def _get_info(id):\n",
    "            \"\"\"Takes an id string and returns the movie info with a url.\"\"\"\n",
    "            try:\n",
    "                c.execute(f\"\"\"\n",
    "                select primary_title, start_year\n",
    "                from movies\n",
    "                where movie_id = '{id[0]}'\"\"\")\n",
    "            except:\n",
    "                return f\"Movie title unknown. ID:{id}\"\n",
    "\n",
    "            t = c.fetchone()\n",
    "            title = tuple([t[0], t[1], f\"https://www.imdb.com/title/tt{id[0]}/\", id[1]])\n",
    "            return title\n",
    "                \n",
    "        def _remove_dislikes(bad_movies, good_movies_vec, input=1, harshness=1):\n",
    "            \"\"\"Takes a list of movies that the user dislikes. \n",
    "            Their embeddings are averaged,\n",
    "            and subtracted from the input.\"\"\"\n",
    "            bad_vec = _aggregate_vectors(bad_movies)\n",
    "            bad_vec = bad_vec / harshness\n",
    "            return good_movies_vec - bad_vec\n",
    "\n",
    "        recs = _aggregate_vectors(input)\n",
    "        recs = _similar_movies(recs, bad_movies, n=n)\n",
    "        recs = _remove_dupes(recs, input, bad_movies)\n",
    "        recs = [_get_info(x) for x in recs]\n",
    "        return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cases\n",
    "\n",
    "# A list of some Coen Bros movies.\n",
    "coen_bros = ['116282', '2042568', '1019452', \n",
    "             '1403865', '190590', '138524', \n",
    "             '335245', '477348', '887883', '101410']\n",
    "\n",
    "# Data scientist's recent watches.\n",
    "cooper_recent = ['0053285', '0038650', '0046022', \n",
    "                 '4520988', '1605783', '6751668', \n",
    "                 '0083791', '0115685', '0051459', \n",
    "                 '8772262', '0061184', '0041959',\n",
    "                 '7775622']\n",
    "\n",
    "# dirkh public letterboxd recent watches.\n",
    "dirkh = ['7975244', '8106534', '1489887', \n",
    "         '1302006', '7286456', '6751668', \n",
    "         '8364368', '2283362', '6146586', \n",
    "         '2194499', '7131622', '6857112']\n",
    "\n",
    "# Marvin watches\n",
    "marvin = ['7286456', '0816692', '2543164', '2935510', \n",
    "          '2798920', '0468569', '5013056', '1375666', \n",
    "          '3659388', '0470752', '0266915', '0092675', \n",
    "          '0137523', '0133093', '1285016']  \n",
    "\n",
    "# Gabe watches\n",
    "gabe = ['6292852','0816692','2737304','3748528',\n",
    "        '3065204','4154796','1536537','1825683',\n",
    "        '1375666','8236336','2488496','1772341',\n",
    "        '0317705','6857112','5052448']\n",
    "\n",
    "# Eric watches\n",
    "eric = ['2974050','1595842','0118539','0093405',\n",
    "        '3216920','1256535','5612742','3120314',\n",
    "        '1893371','0046248','0058548','0199481',\n",
    "        '2296777','0071198','0077834']\n",
    "\n",
    "chuckie = ['4263482',\n",
    "'0084787',\n",
    "'3286052',\n",
    "'5715874',\n",
    "'1172994',\n",
    "'4805316',\n",
    "'3139756',\n",
    "'8772262',\n",
    "'7784604',\n",
    "'1034415',]\n",
    "\n",
    "harlan = ['1065073','5052448','0470752','5688932','1853728','1596363','0432283','6412452','4633694','9495224','0443453','0063823',\n",
    "          '0066921','0405296','1130884','1179933','0120630','0268126','0137523','0374900','8772262','0116996','0107290','7339248']\n",
    "\n",
    "ryan = ['0166924','2866360','0050825','2798920','3416742','0060827','1817273','0338013','0482571','5715874','2316411','4550098']\n",
    "\n",
    "karyn = ['4425200','0464141','1465522','0093779','0099810','0076759','3748528','6763664','0317740','2798920','0096283','0258463','0118799','0058092','0107290','0045152','0106364']\n",
    "\n",
    "richard = ['0074119','0064115','0070735','0080474','0061512','0067774','0057115','0070511','0081283',\n",
    "           '0065126','0068421','0078227','0079100','0078966','0081696','0082085','0072431','0075784',\n",
    "           '0093640','0098051','0094226','0097576','0099810','0081633','0080761','0077975','0085244','0095159','0101969']\n",
    "\n",
    "joe = ['6335734','0291350','0113568','0208502','0169858','0095327','0097814','0983213','0094625','7089878']\n",
    "\n",
    "lena = ['1990314','3236120','1816518','0241527','0097757','0268978','0467406','2543164','2245084','3741834']\n",
    "\n",
    "wade = ['0118665','0270846','0288441','2287250','2287238','8668804','9448868','1702443','1608290','5519340']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ScoringService()\n",
    "good_list_p1 = good_list[:int(len(good_list)/2)]\n",
    "good_list_p2 = good_list[int(len(good_list)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floating Weeds\t1959\n",
      "\thttps://www.imdb.com/title/tt0053390/\n",
      "\tSimilarity: 0.4749234914779663\n",
      "\n",
      "\n",
      "A Moment of Innocence\t1996\n",
      "\thttps://www.imdb.com/title/tt0117214/\n",
      "\tSimilarity: 0.4689294099807739\n",
      "\n",
      "\n",
      "Andrei Rublev\t1966\n",
      "\thttps://www.imdb.com/title/tt0060107/\n",
      "\tSimilarity: 0.46675533056259155\n",
      "\n",
      "\n",
      "Weekend\t1967\n",
      "\thttps://www.imdb.com/title/tt0062480/\n",
      "\tSimilarity: 0.46316659450531006\n",
      "\n",
      "\n",
      "Rampo\t1994\n",
      "\thttps://www.imdb.com/title/tt0110943/\n",
      "\tSimilarity: 0.46307265758514404\n",
      "\n",
      "\n",
      "American Dream\t1990\n",
      "\thttps://www.imdb.com/title/tt0099028/\n",
      "\tSimilarity: 0.4624772071838379\n",
      "\n",
      "\n",
      "Nayak: The Hero\t1966\n",
      "\thttps://www.imdb.com/title/tt0060742/\n",
      "\tSimilarity: 0.4624177813529968\n",
      "\n",
      "\n",
      "La Chinoise\t1967\n",
      "\thttps://www.imdb.com/title/tt0061473/\n",
      "\tSimilarity: 0.46003857254981995\n",
      "\n",
      "\n",
      "Not One Less\t1999\n",
      "\thttps://www.imdb.com/title/tt0209189/\n",
      "\tSimilarity: 0.4561845362186432\n",
      "\n",
      "\n",
      "A Short Film About Killing\t1988\n",
      "\thttps://www.imdb.com/title/tt0095468/\n",
      "\tSimilarity: 0.45157304406166077\n",
      "\n",
      "\n",
      "Sweetie\t1989\n",
      "\thttps://www.imdb.com/title/tt0098725/\n",
      "\tSimilarity: 0.4486675262451172\n",
      "\n",
      "\n",
      "A Scene at the Sea\t1991\n",
      "\thttps://www.imdb.com/title/tt0103704/\n",
      "\tSimilarity: 0.44418391585350037\n",
      "\n",
      "\n",
      "Loves of a Blonde\t1965\n",
      "\thttps://www.imdb.com/title/tt0059415/\n",
      "\tSimilarity: 0.4441092312335968\n",
      "\n",
      "\n",
      "Teorema\t1968\n",
      "\thttps://www.imdb.com/title/tt0063678/\n",
      "\tSimilarity: 0.44090330600738525\n",
      "\n",
      "\n",
      "The Five\t1995\n",
      "\thttps://www.imdb.com/title/tt0113194/\n",
      "\tSimilarity: 0.43989795446395874\n",
      "\n",
      "\n",
      "Beau travail\t1999\n",
      "\thttps://www.imdb.com/title/tt0209933/\n",
      "\tSimilarity: 0.43884414434432983\n",
      "\n",
      "\n",
      "2 or 3 Things I Know About Her\t1967\n",
      "\thttps://www.imdb.com/title/tt0060304/\n",
      "\tSimilarity: 0.4359717071056366\n",
      "\n",
      "\n",
      "Close to Eden\t1991\n",
      "\thttps://www.imdb.com/title/tt0103176/\n",
      "\tSimilarity: 0.43322136998176575\n",
      "\n",
      "\n",
      "A Woman Is a Woman\t1961\n",
      "\thttps://www.imdb.com/title/tt0055572/\n",
      "\tSimilarity: 0.43127232789993286\n",
      "\n",
      "\n",
      "Shadows of Forgotten Ancestors\t1964\n",
      "\thttps://www.imdb.com/title/tt0058642/\n",
      "\tSimilarity: 0.4288187026977539\n",
      "\n",
      "\n",
      "Tokyo Drifter\t1966\n",
      "\thttps://www.imdb.com/title/tt0061101/\n",
      "\tSimilarity: 0.4271097779273987\n",
      "\n",
      "\n",
      "Mother and Son\t1997\n",
      "\thttps://www.imdb.com/title/tt0119711/\n",
      "\tSimilarity: 0.426948606967926\n",
      "\n",
      "\n",
      "Happy Together\t1997\n",
      "\thttps://www.imdb.com/title/tt0118845/\n",
      "\tSimilarity: 0.42637914419174194\n",
      "\n",
      "\n",
      "Last Year at Marienbad\t1961\n",
      "\thttps://www.imdb.com/title/tt0054632/\n",
      "\tSimilarity: 0.4250589907169342\n",
      "\n",
      "\n",
      "Au Hasard Balthazar\t1966\n",
      "\thttps://www.imdb.com/title/tt0060138/\n",
      "\tSimilarity: 0.4223673343658447\n",
      "\n",
      "\n",
      "The Firemen's Ball\t1967\n",
      "\thttps://www.imdb.com/title/tt0061781/\n",
      "\tSimilarity: 0.42185115814208984\n",
      "\n",
      "\n",
      "Shadows\t1958\n",
      "\thttps://www.imdb.com/title/tt0053270/\n",
      "\tSimilarity: 0.42053931951522827\n",
      "\n",
      "\n",
      "Eureka\t2000\n",
      "\thttps://www.imdb.com/title/tt0243889/\n",
      "\tSimilarity: 0.4194139838218689\n",
      "\n",
      "\n",
      "Pierrot le Fou\t1965\n",
      "\thttps://www.imdb.com/title/tt0059592/\n",
      "\tSimilarity: 0.4193999171257019\n",
      "\n",
      "\n",
      "Ratas, ratones, rateros\t1999\n",
      "\thttps://www.imdb.com/title/tt0210249/\n",
      "\tSimilarity: 0.4180571436882019\n",
      "\n",
      "\n",
      "Alphaville\t1965\n",
      "\thttps://www.imdb.com/title/tt0058898/\n",
      "\tSimilarity: 0.4175782799720764\n",
      "\n",
      "\n",
      "The Wind Will Carry Us\t1999\n",
      "\thttps://www.imdb.com/title/tt0209463/\n",
      "\tSimilarity: 0.41685575246810913\n",
      "\n",
      "\n",
      "Sandra\t1965\n",
      "\thttps://www.imdb.com/title/tt0059856/\n",
      "\tSimilarity: 0.41606003046035767\n",
      "\n",
      "\n",
      "Institute Benjamenta, or This Dream That One Calls Human Life\t1995\n",
      "\thttps://www.imdb.com/title/tt0113429/\n",
      "\tSimilarity: 0.4156906008720398\n",
      "\n",
      "\n",
      "Gangster No. 1\t2000\n",
      "\thttps://www.imdb.com/title/tt0210065/\n",
      "\tSimilarity: 0.4135822355747223\n",
      "\n",
      "\n",
      "The Long Day Closes\t1992\n",
      "\thttps://www.imdb.com/title/tt0104753/\n",
      "\tSimilarity: 0.41296839714050293\n",
      "\n",
      "\n",
      "Yi Yi\t2000\n",
      "\thttps://www.imdb.com/title/tt0244316/\n",
      "\tSimilarity: 0.4127048850059509\n",
      "\n",
      "\n",
      "Raining Stones\t1993\n",
      "\thttps://www.imdb.com/title/tt0107920/\n",
      "\tSimilarity: 0.41230496764183044\n",
      "\n",
      "\n",
      "Un Coeur en Hiver\t1992\n",
      "\thttps://www.imdb.com/title/tt0105682/\n",
      "\tSimilarity: 0.41102731227874756\n",
      "\n",
      "\n",
      "Two Men in Manhattan\t1959\n",
      "\thttps://www.imdb.com/title/tt0052733/\n",
      "\tSimilarity: 0.4092755615711212\n",
      "\n",
      "\n",
      "Passing Fancy\t1933\n",
      "\thttps://www.imdb.com/title/tt0023937/\n",
      "\tSimilarity: 0.40823036432266235\n",
      "\n",
      "\n",
      "Schizopolis\t1996\n",
      "\thttps://www.imdb.com/title/tt0117561/\n",
      "\tSimilarity: 0.4048716127872467\n",
      "\n",
      "\n",
      "Eye of God\t1997\n",
      "\thttps://www.imdb.com/title/tt0116261/\n",
      "\tSimilarity: 0.4042065143585205\n",
      "\n",
      "\n",
      "Land and Freedom\t1995\n",
      "\thttps://www.imdb.com/title/tt0114671/\n",
      "\tSimilarity: 0.4033120572566986\n",
      "\n",
      "\n",
      "Underground\t1995\n",
      "\thttps://www.imdb.com/title/tt0114787/\n",
      "\tSimilarity: 0.4032512903213501\n",
      "\n",
      "\n",
      "Maybe... Maybe Not\t1994\n",
      "\thttps://www.imdb.com/title/tt0109255/\n",
      "\tSimilarity: 0.4030874967575073\n",
      "\n",
      "\n",
      "Juliet of the Spirits\t1965\n",
      "\thttps://www.imdb.com/title/tt0059229/\n",
      "\tSimilarity: 0.40258321166038513\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = s.predict(input=good_list_p1, bad_movies=bad_list, n=50, harshness=1)\n",
    "for i in prediction:\n",
    "    print(f\"{i[0]}\\t{i[1]}\\n\\t{i[2]}\\n\\tSimilarity: {i[3]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Word2VecWatchHistory_3_filter.ipynb",
   "provenance": [
    {
     "file_id": "1wKOz0h5GIZN3G-qdUfgCEuwJLScSixpN",
     "timestamp": 1578946551815
    }
   ]
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
