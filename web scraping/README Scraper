# Web Scraping

General overview of our process, why we made certain choices, and what data is ultimately being fed into our DB.


## Quick Rundown of the Scraper

As of (12/13/19) this scraper uses a list of movie IDs which were pulled from the tarbal files published by IMDb to return movie reviews and ratings.

In addition to reviews and ratings, the scraper pulls some information which will not be implemented in the initial skeleton model, but which may be used in the future model iterations.
(Date of review, How many people found review helpful, etc.)

### Blockers

12/13/19 - We hit a snag which prevents us from populating the RDS DB tables with data output from the scraper. We believe it is isolated to a misconfiguration of


### Installing

In order to run you will need to setup an AWS RDS DB

(Todo: walkthrough setup of AWS RDS DB and give overview of current table structure)

## Deployment

Run:
```
python3 scraper.py
```

## Built With

* [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) - Python Library for pulling HTML data
* [psycopg2](https://pypi.org/project/psycopg2/) - PostgresSQL database adapter
* [Amazon RDS](https://aws.amazon.com/rds/?nc2=h_ql_prod_fs_rds) - The scraper outputs into two RDS DB tables
